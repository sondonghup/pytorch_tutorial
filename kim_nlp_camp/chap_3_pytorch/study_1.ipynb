{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(2,2)\n",
    "print(x)\n",
    "x = torch.Tensor([[1, 2], [3, 4]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [3, 4]]\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "x = [[1, 2], [3, 4]]\n",
    "print(x)\n",
    "x = np.array(x)\n",
    "print(x)\n",
    "x = torch.from_numpy(x)\n",
    "print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[1., 3.],\n",
      "        [5., 7.]])\n",
      "tensor([[1., 3.],\n",
      "        [5., 7.]], requires_grad=True)\n",
      "tensor([[ 3.,  9.],\n",
      "        [11., 14.]], grad_fn=<AddBackward0>)\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[1., 3.],\n",
      "        [5., 7.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(x)\n",
    "y = torch.FloatTensor([[1, 3], [5, 7]])\n",
    "print(y)\n",
    "y.requires_grad_(True)\n",
    "print(y)\n",
    "z = (x + y) + torch.FloatTensor([[1, 4], [3, 3]])\n",
    "print(z)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[1., 3.],\n",
      "        [5., 7.]])\n",
      "tensor([[1., 3.],\n",
      "        [5., 7.]], requires_grad=True)\n",
      "tensor([[ 3.,  9.],\n",
      "        [11., 14.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(x)\n",
    "y = torch.FloatTensor([[1, 3], [5, 7]])\n",
    "print(y)\n",
    "y.requires_grad_(True)\n",
    "print(y)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = (x + y) + torch.FloatTensor([[1, 4], [3, 3]])\n",
    "    print(z)\n",
    "    print(x)\n",
    "    print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15., 22.],\n",
      "        [23., 33.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1, 2, 3], [2, 3, 4]])\n",
    "y = torch.FloatTensor([[1, 2], [2, 3], [3, 4]])\n",
    "z = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "\n",
    "def linear(x, y, z):\n",
    "    result = torch.mm(x, y) + z\n",
    "    return result\n",
    "\n",
    "print(linear(x, y, z))\n",
    "# mm -> matrix multiplication\n",
    "# bmm -> batch matrix multiplication\n",
    "# matmul -> matrix, batch matrix multiplication"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 6.6021e-07, 1.7185e-04],\n",
      "        [1.9635e-10, 1.9979e-10, 6.6041e-07, 1.7185e-04],\n",
      "        [0.0000e+00, 0.0000e+00, 6.6021e-07, 1.7185e-04],\n",
      "        [0.0000e+00, 0.0000e+00, 6.6021e-07, 1.7185e-04]])\n"
     ]
    }
   ],
   "source": [
    "class mylinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.w = torch.FloatTensor(input_size, output_size)\n",
    "        self.b = torch.FloatTensor(output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.mm(x, self.w) + self.b\n",
    "        \n",
    "linear = mylinear(2, 4)\n",
    "result = linear(torch.FloatTensor(4, 2))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "params = [p for p in linear.parameters()]\n",
    "print(params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "빈 배열이 나오는 이유는 학습 가능한 파라미터가 없기 때문\n",
    "-> parameter객체로 텐서를 감싸야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.b Parameter containing:\n",
      "tensor([0., 0., 0., 0.], requires_grad=True)\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.3221e+13, 4.3370e+28,        inf,        inf],\n",
      "        [6.4999e-21, 1.4923e-09, 1.2102e+19, 3.3221e+13],\n",
      "        [1.6546e-18, 1.2136e-07, 9.8422e+20, 2.7017e+15]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class mylinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(mylinear, self).__init__()\n",
    "\n",
    "        self.w = nn.Parameter(torch.FloatTensor(input_size, output_size))\n",
    "        self.b = nn.Parameter(torch.FloatTensor(output_size))\n",
    "        print('self.b', self.b)\n",
    "    def forward(self, x):\n",
    "        return torch.mm(x, self.w) + self.b\n",
    "\n",
    "linear = mylinear(2, 4)\n",
    "result = linear(torch.FloatTensor(4, 2))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[28., 39.],\n",
      "        [36., 51.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class mylinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(mylinear, self).__init__()\n",
    "\n",
    "        self.w = nn.Parameter(torch.FloatTensor([[1, 2], [3, 4]]))\n",
    "        self.b = nn.Parameter(torch.FloatTensor([[5, 5], [5, 5]]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.mm(x, self.w) + self.b\n",
    "\n",
    "linear = mylinear(2, 4)\n",
    "result = linear(torch.FloatTensor([[5, 6], [7, 8]]))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], requires_grad=True), Parameter containing:\n",
      "tensor([[5., 5.],\n",
      "        [5., 5.]], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "params = [p for p in linear.parameters()]\n",
    "print(params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "backward 역전파"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(10816., grad_fn=<PowBackward0>)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "objective = 50\n",
    "\n",
    "loss = (objective - result.sum())**2\n",
    "print('loss', loss)\n",
    "print(loss.backward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.3614e-01,  2.5292e-01, -4.3508e-01, -4.7283e-01],\n",
      "        [ 6.3614e-01,  2.5292e-01, -4.3508e-01, -4.7283e-01],\n",
      "        [ 6.3614e-01,  2.5292e-01, -4.3508e-01, -4.7283e-01],\n",
      "        [-1.4185e+20, -7.0060e+18,  1.2350e+20, -7.7721e+19]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "linear = nn.Linear(2, 4)\n",
    "result = linear(torch.FloatTensor(4, 2))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mymodel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Mymodel, self).__init__()\n",
    "\n",
    "        self.linear = nn.Linear(input_size, output_size, True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def ground_truth(x):\n",
    "    return 3 * x[: 0] + x[: 1] - 2 * x [: 2]\n",
    "\n",
    "def train(model, x, y, optim):\n",
    "    optim.zero_grad()\n",
    "\n",
    "    y_hat = model(x)\n",
    "\n",
    "    loss = ((y - y_hat)**2).sum() / x.size(0)\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    optim.step()\n",
    "\n",
    "    return loss.data\n",
    "\n",
    "def valid(model, x, y, optim):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        y_hat = model(x)\n",
    "\n",
    "        loss = ((y - y_hat)**2).sum() / x.size(0)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "        return loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mymodel(\n",
      "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "n_epochs = 1000\n",
    "n_iter = 10000\n",
    "\n",
    "model = Mymodel(3, 1)\n",
    "optim = torch.optim.SGD(model.parameters(), lr = 0.0001, momentum = 0.1)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.0146, 0.6631, 0.1364]])\n",
      "x.data tensor([[0.0146, 0.6631, 0.1364]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m, x)\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mx.data\u001b[39m\u001b[39m'\u001b[39m, x\u001b[39m.\u001b[39mdata)\n\u001b[1;32m----> 8\u001b[0m \u001b[39minput\u001b[39;49m()\n\u001b[0;32m      9\u001b[0m y \u001b[39m=\u001b[39m ground_truth(x\u001b[39m.\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Users\\a\\anaconda3\\envs\\acer\\lib\\site-packages\\ipykernel\\kernelbase.py:1177\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_allow_stdin:\n\u001b[0;32m   1174\u001b[0m     \u001b[39mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[0;32m   1175\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1176\u001b[0m     )\n\u001b[1;32m-> 1177\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_request(\n\u001b[0;32m   1178\u001b[0m     \u001b[39mstr\u001b[39;49m(prompt),\n\u001b[0;32m   1179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent_ident[\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1180\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_parent(\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1181\u001b[0m     password\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1182\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\a\\anaconda3\\envs\\acer\\lib\\site-packages\\ipykernel\\kernelbase.py:1219\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1216\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1218\u001b[0m     \u001b[39m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m-> 1219\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInterrupted by user\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m   1220\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1221\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mInvalid Message:\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    avg_loss = 0\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        x = torch.rand(batch_size, 3)\n",
    "        y = ground_truth(x.data)\n",
    "\n",
    "        loss = train(model, x, y, optim)\n",
    "\n",
    "        avg_loss += loss\n",
    "    avg_loss = avg_loss/n_iter\n",
    "\n",
    "    x_valid = torch.FloatTensor([[.3, .2, .1]])\n",
    "    y_valid = ground_truth(x_valid.data)\n",
    "\n",
    "    valid_loss = \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c14f28fee4a2d56a0a92739f317b348643c5fc323156148e4cf6a32831accdcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
